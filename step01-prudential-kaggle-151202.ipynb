{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/prudential-life-insurance-assessment/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate train and test data into one dataframe for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training set = 59381 observations\n",
      "length of testing set = 19765 observations\n",
      "correctly concatenated train and test data  =>  num. observations = 79146\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "sample_out = pd.read_csv('input/sample_submission.csv')\n",
    "\n",
    "train['train?'] = True\n",
    "test['train?'] = False\n",
    "\n",
    "print(\"length of training set = {:d} observations\".format(len(train)))\n",
    "print(\"length of testing set = {:d} observations\".format(len(test)))\n",
    "\n",
    "data = pd.concat((train,test)).reset_index(drop=True)\n",
    "\n",
    "assert len(data) == len(train) + len(test)\n",
    "print(\"correctly concatenated train and test data  =>  num. observations = {:d}\".format(len(data)))\n",
    "\n",
    "data_features = data.drop(['Response', 'train?'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "print(len(data_features.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List features that have null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Employment_Info_1': 22,\n",
       " 'Employment_Info_4': 8916,\n",
       " 'Employment_Info_6': 14641,\n",
       " 'Family_Hist_2': 38536,\n",
       " 'Family_Hist_3': 45305,\n",
       " 'Family_Hist_4': 25861,\n",
       " 'Family_Hist_5': 55435,\n",
       " 'Insurance_History_5': 33501,\n",
       " 'Medical_History_1': 11861,\n",
       " 'Medical_History_10': 78388,\n",
       " 'Medical_History_15': 59460,\n",
       " 'Medical_History_24': 74165,\n",
       " 'Medical_History_32': 77688}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_with_nulls = {k:v for k, v in data_features.isnull().apply(sum).to_dict().items() if v > 0}\n",
    "features_with_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that `Product_Info_2` in fact has categorical values.  Is it the only feature with non-numeric values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List features with non-numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-mumerical columns = {'Product_Info_2': dtype('O')}\n"
     ]
    }
   ],
   "source": [
    "# Is Product_Info_2 the only non-numerical feature?\n",
    "nonnum = {col: train.dtypes[col] for col in data_features.columns if data_features.dtypes[col] not in [np.dtype('int64'), np.dtype('float64')]}\n",
    "print(\"non-mumerical columns = {}\".format(nonnum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List features with values < 0 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Product_Info_2': 79146}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features that have < 0 values:\n",
    "{k:v for k, v in (data_features < 0).apply(sum).to_dict().items() if v > 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a closer look at the values in `Product_Info_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique vals = ['D3' 'A1' 'E1' 'D4' 'D2' 'A8' 'A2' 'D1' 'A7' 'A6' 'A3' 'A5' 'C4' 'C1' 'B2'\n",
      " 'C3' 'C2' 'A4' 'B1']\n",
      "num unique = 19\n",
      "\n",
      "\n",
      "A1 - 2363 observations\n",
      "{1: 132, 2: 235, 3: 51, 4: 68, 5: 195, 6: 352, 7: 270, 8: 1060}\n",
      "\n",
      "A2 - 1974 observations\n",
      "{1: 238, 2: 267, 3: 20, 4: 39, 5: 149, 6: 415, 7: 276, 8: 570}\n",
      "\n",
      "A3 - 977 observations\n",
      "{1: 70, 2: 104, 3: 17, 4: 31, 5: 64, 6: 156, 7: 124, 8: 411}\n",
      "\n",
      "A4 - 210 observations\n",
      "{1: 19, 3: 4, 4: 10, 5: 17, 6: 34, 7: 30, 8: 96}\n",
      "\n",
      "A5 - 775 observations\n",
      "{1: 53, 3: 13, 4: 28, 5: 42, 6: 126, 7: 138, 8: 375}\n",
      "\n",
      "A6 - 2098 observations\n",
      "{1: 122, 3: 26, 4: 44, 5: 122, 6: 327, 7: 296, 8: 1161}\n",
      "\n",
      "A7 - 1383 observations\n",
      "{1: 281, 2: 285, 3: 94, 4: 4, 5: 662, 6: 12, 7: 15, 8: 30}\n",
      "\n",
      "A8 - 6835 observations\n",
      "{1: 953, 2: 728, 3: 110, 4: 89, 5: 927, 6: 1086, 7: 965, 8: 1977}\n",
      "\n",
      "B1 - 54 observations\n",
      "{1: 7, 3: 9, 4: 6, 5: 8, 6: 11, 7: 5, 8: 8}\n",
      "\n",
      "B2 - 1122 observations\n",
      "{1: 74, 2: 38, 3: 11, 4: 21, 5: 76, 6: 182, 7: 173, 8: 547}\n",
      "\n",
      "C1 - 285 observations\n",
      "{1: 45, 2: 40, 3: 9, 4: 13, 5: 19, 6: 47, 7: 39, 8: 73}\n",
      "\n",
      "C2 - 160 observations\n",
      "{1: 22, 2: 28, 3: 5, 4: 5, 5: 11, 6: 25, 7: 24, 8: 40}\n",
      "\n",
      "C3 - 306 observations\n",
      "{1: 33, 2: 28, 3: 10, 4: 10, 5: 24, 6: 61, 7: 48, 8: 92}\n",
      "\n",
      "C4 - 219 observations\n",
      "{1: 19, 2: 17, 3: 2, 4: 7, 5: 14, 6: 35, 7: 27, 8: 98}\n",
      "\n",
      "D1 - 6554 observations\n",
      "{1: 1065, 2: 1275, 3: 169, 4: 277, 5: 435, 6: 1316, 7: 738, 8: 1279}\n",
      "\n",
      "D2 - 6286 observations\n",
      "{1: 746, 2: 917, 3: 110, 4: 154, 5: 423, 6: 1542, 7: 921, 8: 1473}\n",
      "\n",
      "D3 - 14321 observations\n",
      "{1: 1440, 2: 1675, 3: 237, 4: 420, 5: 1256, 6: 3281, 7: 2080, 8: 3932}\n",
      "\n",
      "D4 - 10812 observations\n",
      "{1: 687, 2: 707, 3: 82, 4: 124, 5: 810, 6: 1797, 7: 1457, 8: 5148}\n",
      "\n",
      "E1 - 2647 observations\n",
      "{1: 201, 2: 208, 3: 34, 4: 78, 5: 178, 6: 428, 7: 401, 8: 1119}\n"
     ]
    }
   ],
   "source": [
    "col = 'Product_Info_2'\n",
    "print(\"unique vals = {}\".format(train[col].unique()))\n",
    "print(\"num unique = {}\".format(len(train[col].unique())))\n",
    "print()\n",
    "\n",
    "for val in sorted(train[col].unique()):\n",
    "    val_set = train[train[col]==val]\n",
    "    print(\"\\n{} - {} observations\".format(val, len(val_set)))\n",
    "    print(val_set.groupby('Response').size().to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the values of `Product_Info_2` have no ordering, so at the end we will keep this in mind and make it a one-hot encoded variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's take a closer look at the features that have null values\n",
    "\n",
    "To do this we start by defining a function that allows us to take a quick glance at a particular feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def explore_feature(dataframe, col):\n",
    "    with io.StringIO(\"\") as fout:\n",
    "        \n",
    "        \n",
    "        print(\"\\n\\n\" + \"=\"*50, file=fout)\n",
    "        print(\"column name = {}, dtype = {}\".format(col, dataframe.dtypes[col]), file=fout)\n",
    "        print(\"-\"*40, file=fout)\n",
    "        print(\"value counts:\", file=fout)\n",
    "        if len(dataframe[col].unique()) > 50:\n",
    "            print(\"\\t>> more than 50 unique values <<\", file=fout)\n",
    "        else:\n",
    "            low_frequency_values = []\n",
    "            for index,value in dataframe[col].value_counts().iteritems():\n",
    "                if value > 1000:\n",
    "                    print(\"{:s} {:s}\".format(str(index).ljust(10), str(value).rjust(6)), file=fout)\n",
    "                else:\n",
    "                    low_frequency_values.append(\"{0}({1})\".format(str(index), value))\n",
    "            if len(low_frequency_values) > 0:\n",
    "                print(\"values with < 1000 counts: [{}]\".format(', '.join(low_frequency_values)), file=fout)\n",
    "\n",
    "        print(\"-\"*50, file=fout)\n",
    "        stats = dataframe[col].describe()\n",
    "        try:\n",
    "            strstats = ', '.join(\"{}:{:.2g}\".format(k, float(v)) for k, v in stats.items() if k != 'count')\n",
    "        except:\n",
    "            strstats = None\n",
    "\n",
    "\n",
    "        if strstats is not None:\n",
    "            print(strstats, file=fout)\n",
    "                      \n",
    "        column_info = fout.getvalue()\n",
    "        return column_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our `explore_feature` function let's take a close look at those features that have null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "column name = Employment_Info_4, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:0.0063, std:0.033, min:0, 25%:0, 50%:0, 75%:0, max:1\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Employment_Info_6, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:0.36, std:0.35, min:0, 25%:0.06, 50%:0.25, 75%:0.58, max:1\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Family_Hist_5, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:0.49, std:0.13, min:0, 25%:0.41, 50%:0.51, 75%:0.58, max:1\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Medical_History_1, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:7.9, std:13, min:0, 25%:2, 50%:4, 75%:9, max:2.4e+02\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Family_Hist_4, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:0.45, std:0.16, min:0, 25%:0.32, 50%:0.44, 75%:0.56, max:1\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Family_Hist_3, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:0.5, std:0.14, min:0, 25%:0.41, 50%:0.52, 75%:0.61, max:1\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Employment_Info_1, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:0.078, std:0.083, min:0, 25%:0.035, 50%:0.06, 75%:0.1, max:1\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Medical_History_15, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:1.2e+02, std:99, min:0, 25%:18, 50%:1.2e+02, 75%:2.4e+02, max:2.4e+02\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Medical_History_32, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:12, std:38, min:0, 25%:0, 50%:0, 75%:2, max:2.4e+02\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Medical_History_10, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:1.4e+02, std:1.1e+02, min:0, 25%:9.2, 50%:2.2e+02, 75%:2.4e+02, max:2.4e+02\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Insurance_History_5, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:0.0017, std:0.0065, min:0, 25%:0.0004, 50%:0.00093, 75%:0.002, max:1\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Family_Hist_2, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:0.47, std:0.15, min:0, 25%:0.36, 50%:0.46, 75%:0.58, max:1\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "column name = Medical_History_24, dtype = float64\n",
      "----------------------------------------\n",
      "value counts:\n",
      "\t>> more than 50 unique values <<\n",
      "--------------------------------------------------\n",
      "mean:50, std:78, min:0, 25%:1, 50%:8, 75%:63, max:2.4e+02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in features_with_nulls.items():\n",
    "    print(explore_feature(data, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can see that all of the features that have nulls are continuous features, with values greater than zero.  We will go ahead and impute all of the nulls with a value of minus one. (A tree can then easily cut out NaN's separately from the rest of the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79146\n"
     ]
    }
   ],
   "source": [
    "noprod = data.drop(['Product_Info_2'], axis=1)\n",
    "dummies = pd.get_dummies(data['Product_Info_2'])\n",
    "\n",
    "df = noprod.join(dummies).drop(['Response', 'train?'], axis=1).fillna(-1).join(data[['Response', 'train?']])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that all of the training data indeed falls into one of the 8 categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.,  4.,  1.,  6.,  2.,  7.,  3.,  5.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['train?'] == True]['Response'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imputed null values and one-hot encoded the Product_Info_2 categorical feature we can proceed to train an ensemble.\n",
    "\n",
    "### But before moving on we save the imputed data set to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('csvs/data_imputed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
