{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ml_metrics import quadratic_weighted_kappa\n",
    "import xgboost as xgb\n",
    "import datetime as dt\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "import functools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score\n",
    "from scipy import optimize\n",
    "\n",
    "from xgboostmodel import XGBoostModel, ModelPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 03.  Optimized classification\n",
    "\n",
    "### Goal 1: Implement class which allows easy combination of boosters to make predictions\n",
    "\n",
    "### Goal 2: Optimize the classify function, that converst scores to categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start out by fitting our best `reg:linear` and `multi:softmax` models which we obtained in Step 02:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273198\n",
      "         Iterations: 11\n",
      "         Function evaluations: 1168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objective</th>\n",
       "      <th>train_qwk</th>\n",
       "      <th>test_qwk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reg:linear</td>\n",
       "      <td>0.726802</td>\n",
       "      <td>0.649477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>0.615971</td>\n",
       "      <td>0.550655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       objective  train_qwk  test_qwk\n",
       "0     reg:linear   0.726802  0.649477\n",
       "1  multi:softmax   0.615971  0.550655"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booster = XGBoostModel(nfolds=3)\n",
    "\n",
    "fold = 1 # the fold to use for train-test split\n",
    "\n",
    "booster.learn_model(fold, objective='reg:linear', num_round=250, \n",
    "                    make_plot=False,\n",
    "                    eta=0.06,\n",
    "                    max_depth=9,\n",
    "                    min_child_weight=150,\n",
    "                    colsample_bytree=0.8,\n",
    "                    subsample=0.8)\n",
    "\n",
    "booster.learn_model(fold, objective='multi:softmax', num_round=250, \n",
    "                    make_plot=False,\n",
    "                    eta=0.06,\n",
    "                    max_depth=8,\n",
    "                    min_child_weight=50,\n",
    "                    colsample_bytree=0.8,\n",
    "                    subsample=0.8)\n",
    "\n",
    "booster.get_scores()[['objective', 'train_qwk', 'test_qwk']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We define the ComboPredict class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "\n",
    "class ComboPredict:\n",
    "    \n",
    "    def __init__(self, booster):\n",
    "        \"\"\"\n",
    "        Intitialize the combination predictor with an XGBoostModel instance\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        booster : XGBoostModel\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.booster = booster\n",
    "        \n",
    "        if (len(self.booster.models) == 0):\n",
    "            raise ValueError(\"The XGBoostModel provided does not contain any \"\n",
    "                             \"fitted models.\")\n",
    "        \n",
    "        \n",
    "    def predict_score(self, features, overall_cls_factor):\n",
    "        \"\"\"\n",
    "        Predicts scores for a set of observations.  The score is calculated\n",
    "        by weighting all of the models present in the XGBoostModel that is \n",
    "        passed into the class at initialization. \n",
    "        \n",
    "        Note that the scores output by this function need to be coerced to\n",
    "        category values for a final prediction. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        features : array\n",
    "        \n",
    "            Features for which predictions weill be generated\n",
    "            \n",
    "        overall_cls_factor : float\n",
    "        \n",
    "            Relative weight of the classification boosters wrt to the regression\n",
    "            boosters\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        xg_input = xgb.DMatrix(features)\n",
    "\n",
    "        weighted_preds = []\n",
    "        norms = []\n",
    "        for m in zip(booster.models, booster.scores):\n",
    "            model, model_fold, model_pred = m[0]\n",
    "            score = m[1]\n",
    "\n",
    "            nfeatures = xg_input.num_row()\n",
    "            X, _ = np.meshgrid(np.arange(8), np.arange(nfeatures))\n",
    "\n",
    "            if score['objective'] == 'multi:softmax':\n",
    "                pred_cls = model.predict(xg_input,\n",
    "                                         ntree_limit=model.best_iteration)\n",
    "                dummies = pd.get_dummies(pred_cls).values\n",
    "                weight = model_pred.precisiontrain.reshape(8,1) \n",
    "\n",
    "                weighted_pred = np.dot(X * dummies, overall_cls_factor * weight)\n",
    "                weighted_preds.append(weighted_pred)\n",
    "\n",
    "                norm = np.dot(dummies, overall_cls_factor * weight )\n",
    "                norms.append(norm)\n",
    "\n",
    "            else:\n",
    "                reg_pred = model.predict(xg_input,\n",
    "                                         ntree_limit=model.best_iteration)\n",
    "                weighted_preds.append(reg_pred.reshape(nfeatures, 1))\n",
    "                norms.append(np.ones_like(weighted_preds))\n",
    "\n",
    "        total = np.sum(weighted_preds, axis=0) \n",
    "        norm = np.sum(norms, axis=0)\n",
    "\n",
    "        combo_score = np.squeeze(total / norm)\n",
    "        return combo_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We demonstrate the use of `ComboPredict` to calculate scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combo = ComboPredict(booster)\n",
    "\n",
    "# All of the models in booster were trained with fold=1:\n",
    "assert all(fold == 1 for _, fold, _ in booster.models)\n",
    "\n",
    "# We get the features and labels for fold=1\n",
    "train, test = booster.make_cv_split(1, returnxgb=False)\n",
    "# train, test are each a tuple of the form (features, labels)\n",
    "\n",
    "overall_cls_factor = 0.4\n",
    "score_train = combo.predict_score(train[0], overall_cls_factor)\n",
    "score_test = combo.predict_score(test[0], overall_cls_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use rounding to the neareset integer to produce categories, and we check kappa for the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train qwk = 0.67922\n",
      " test qwk = 0.60933\n"
     ]
    }
   ],
   "source": [
    "def classify(score):\n",
    "    score = np.asarray(score)\n",
    "    return np.rint(np.clip(score, -0.49, 7.49))\n",
    "\n",
    "yhcombotrain = classify(score_train)\n",
    "yhcombotest = classify(score_test)\n",
    "\n",
    "print(\"train qwk = {:0.5f}\".format(quadratic_weighted_kappa(yhcombotrain, \n",
    "                                                            train[1])))\n",
    "\n",
    "print(\" test qwk = {:0.5f}\".format(quadratic_weighted_kappa(yhcombotest, \n",
    "                                                            test[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recover the results of Step 02, where it was shown that using a weighing ratio 0.4:1 (classification:regression) contribution to the score was beneficial for the quadratic weighted kappa of our predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with cutoffs\n",
    "\n",
    "Rather than rounding to the nearest integer, we implement a function that allows setting score cuttofs which map to each of the eight possible categories: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLES OF classify_with_cutoffs:\n",
      "\n",
      "score=0.97 => category=1\n",
      "score=4.48 => category=4\n",
      "score=3.84 => category=4\n",
      "score=5.49 => category=5\n",
      "score=5.51 => category=6\n"
     ]
    }
   ],
   "source": [
    "def classify_with_cutoffs(yscore, cutoffs):\n",
    "    \"\"\"\n",
    "    Receives a list of seven cutoffs, which will determine the mapping from \n",
    "    scores to categories.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    predicted_score : array\n",
    "    \n",
    "        Array of predicted scores, which will be mapped onto categories \n",
    "        according to cutoffs\n",
    "    \n",
    "    cutoffs : array \n",
    "    \n",
    "        Array of length 7 (num_categories - 1).  \n",
    "    \"\"\"\n",
    "    assert len(cutoffs) == 7\n",
    "    cutoffs = np.sort(cutoffs)\n",
    "    return np.digitize(yscore, cutoffs).astype('int')\n",
    "    \n",
    "    \n",
    "print(\"EXAMPLES OF classify_with_cutoffs:\\n\")\n",
    "cutoffs0 = np.arange(7)+0.5\n",
    "for val in list(np.random.rand(3)*9. -2.) + [5.49, 5.51]:\n",
    "    cat = classify_with_cutoffs(val, cutoffs0)\n",
    "    print(\"score={:.2f} => category={}\".format(val, cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We define a function for optimizing the cutoffs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cutoffs get \"trained\" based on the calculated score and the known true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNOPTIMIZED:\n",
      "\n",
      " qwk = 0.6792\n",
      "\n",
      "================================================================================\n",
      "    start error : 1.704812979226756\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.696007\n",
      "         Iterations: 9\n",
      "         Function evaluations: 839\n",
      "    final error : 1.6960072842910539\n",
      "\n",
      "OPTIMIZED CUTOFFS LSTSQ:\n",
      "[ 0.32229194  1.63951265  2.67249365  3.63436993  4.76973765  5.63572747\n",
      "  6.37087037]\n",
      "\n",
      " qwk = 0.6934\n",
      "\n",
      "================================================================================\n",
      "    start error : 0.3207754330380226\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.276877\n",
      "         Iterations: 9\n",
      "         Function evaluations: 808\n",
      "    final error : 0.2768769249311198\n",
      "\n",
      "OPTIMIZED CUTOFFS QWK:\n",
      "[ 1.8277727   2.67539148  3.26617627  3.9487634   4.79714536  5.46358664\n",
      "  6.07641931]\n",
      "\n",
      " qwk = 0.7231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def optmize_cutoffs_simplex(yscore, ytrue, errorfun, *, verbose=False):\n",
    "    \"\"\"\n",
    "    Receives an array of predicted scores, and an array of true values. \n",
    "    Determines which cutoff values make for the best prediction with\n",
    "    respect to the true values. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    yscore : array\n",
    "        \n",
    "        Array of predicted scores\n",
    "        \n",
    "    ytrue : array\n",
    "    \n",
    "        Array of true  values \n",
    "        \n",
    "    verbose : bool (optional) \n",
    "    \n",
    "        When true prints the std dev of y-ypred before and after \n",
    "        optimization.   \n",
    "    \"\"\"\n",
    "    \n",
    "    yscore = np.asarray(yscore, dtype=np.float64)\n",
    "    ytrue = np.asarray(ytrue, dtype=np.float64)\n",
    "    \n",
    "    def error(p):\n",
    "        return errorfun(p, yscore, ytrue)\n",
    "    \n",
    "    cutoffs0 = np.arange(7)+0.5\n",
    "    \n",
    "    just = 15\n",
    "    if verbose:\n",
    "        print(\"{} : {}\".format(\n",
    "                \"start error\".rjust(just), error(cutoffs0)))\n",
    "    \n",
    "    #xopt, fopt, niter, funcalls, warnflag, allvecs \n",
    "    pfit = optimize.fmin_powell(error, cutoffs0, xtol=1e-2, ftol=1e-6, \n",
    "                                maxiter=None, maxfun=None)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"{} : {}\\n\".format(\n",
    "                \"final error\".rjust(just), error(pfit)))\n",
    "        \n",
    "    return np.sort(pfit)\n",
    "\n",
    "\n",
    "def error_lstsq(p, yscore, ytrue):\n",
    "    errors = classify_with_cutoffs(yscore, p).astype(np.float64) - ytrue\n",
    "    return np.std(errors)\n",
    "\n",
    "print(\"UNOPTIMIZED:\")\n",
    "print(\"\\n qwk = {:0.4f}\\n\".format(\n",
    "        quadratic_weighted_kappa(classify(score_train).astype(np.int64), train[1])\n",
    "    ))\n",
    "\n",
    "print(\"=\"*80)\n",
    "pfit = optmize_cutoffs_simplex(score_train, train[1], error_lstsq, verbose=True)\n",
    "print(\"OPTIMIZED CUTOFFS LSTSQ:\")\n",
    "print(pfit)\n",
    "bestpfit_leastsq = pfit\n",
    "print(\"\\n qwk = {:0.4f}\\n\".format(\n",
    "        quadratic_weighted_kappa(classify_with_cutoffs(score_train, bestpfit_leastsq), train[1])\n",
    "    ))\n",
    "\n",
    "\n",
    "def error_qwk(p, yscore, ytrue):\n",
    "    errors = quadratic_weighted_kappa(classify_with_cutoffs(yscore, p).astype(np.int64), ytrue)\n",
    "    return 1 - errors\n",
    "\n",
    "print(\"=\"*80)\n",
    "pfit = optmize_cutoffs_simplex(score_train, train[1], error_qwk, verbose=True)\n",
    "print(\"OPTIMIZED CUTOFFS QWK:\")\n",
    "print(pfit)\n",
    "bestpfit_qwk = pfit\n",
    "print(\"\\n qwk = {:0.4f}\\n\".format(\n",
    "        quadratic_weighted_kappa(classify_with_cutoffs(score_train, bestpfit_qwk), train[1])\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7231230750688802\n"
     ]
    }
   ],
   "source": [
    "print(quadratic_weighted_kappa(classify_with_cutoffs(score_train, pfit).astype(np.int64), train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNOPTIMIZED:\n",
      "train qwk = 0.67922\n",
      " test qwk = 0.60933\n",
      "================================================================================\n",
      "OPTIMIZED LEASTSQ:\n",
      "train qwk = 0.69342\n",
      " test qwk = 0.61843\n",
      "================================================================================\n",
      "OPTIMIZED QWK:\n",
      "train qwk = 0.72312\n",
      " test qwk = 0.64827\n"
     ]
    }
   ],
   "source": [
    "yhcombotrain = classify(score_train)\n",
    "yhcombotest = classify(score_test)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"UNOPTIMIZED:\")\n",
    "print(\"train qwk = {:0.5f}\".format(quadratic_weighted_kappa(yhcombotrain, \n",
    "                                                            train[1])))\n",
    "print(\" test qwk = {:0.5f}\".format(quadratic_weighted_kappa(yhcombotest, \n",
    "                                                            test[1])))\n",
    "\n",
    "yhcombotrain = classify_with_cutoffs(score_train, bestpfit_leastsq)\n",
    "yhcombotest = classify_with_cutoffs(score_test, bestpfit_leastsq)\n",
    "print(\"=\"*80)\n",
    "print(\"OPTIMIZED LEASTSQ:\")\n",
    "print(\"train qwk = {:0.5f}\".format(quadratic_weighted_kappa(yhcombotrain, \n",
    "                                                            train[1])))\n",
    "print(\" test qwk = {:0.5f}\".format(quadratic_weighted_kappa(yhcombotest, \n",
    "                                                            test[1])))\n",
    "\n",
    "yhcombotrain = classify_with_cutoffs(score_train, bestpfit_qwk)\n",
    "yhcombotest = classify_with_cutoffs(score_test, bestpfit_qwk)\n",
    "print(\"=\"*80)\n",
    "print(\"OPTIMIZED QWK:\")\n",
    "print(\"train qwk = {:0.5f}\".format(quadratic_weighted_kappa(yhcombotrain, \n",
    "                                                            train[1])))\n",
    "print(\" test qwk = {:0.5f}\".format(quadratic_weighted_kappa(yhcombotest, \n",
    "                                                            test[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know go back to the submission samples and make a prediction based on our current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19765.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.721882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.804223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Response\n",
       "count  19765.000000\n",
       "mean       5.721882\n",
       "std        1.804223\n",
       "min        1.000000\n",
       "25%        5.000000\n",
       "50%        6.000000\n",
       "75%        7.000000\n",
       "max        8.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('csvs/data_imputed.csv')\n",
    "features = data[data['train?'] == True].drop(['train?', 'Id', 'Response'], \n",
    "                                             axis=1)\n",
    "\n",
    "labels = data[data['train?'] == True]['Response'].astype('int') -1 \n",
    "\n",
    "submission_features = data[data['train?'] == False].drop(['train?', \n",
    "                                                          'Id', \n",
    "                                                          'Response'], \n",
    "                                                         axis=1)\n",
    "\n",
    "combo = ComboPredict(booster)\n",
    "\n",
    "# All of the models in booster were trained with fold=1:\n",
    "assert all(fold == 1 for _, fold, _ in booster.models)\n",
    "\n",
    "overall_cls_factor = 0.4\n",
    "score_submission = combo.predict_score(submission_features, overall_cls_factor)\n",
    "\n",
    "best_cutoffs = np.array([ 0.3223,  1.6395,  2.6725,  3.6344,  \n",
    "                         4.7697,  5.6357,  6.3709])\n",
    "yhcombo_submission = classify_with_cutoffs(score_submission, best_cutoffs)\n",
    "\n",
    "submission_ids = data[data['train?'] == False]['Id']\n",
    "submission_df = pd.DataFrame({\"Id\": submission_ids, \n",
    "                              \"Response\": yhcombo_submission.astype('int') + 1})\n",
    "\n",
    "submission_df = submission_df.set_index('Id')\n",
    "submission_df.to_csv('step03_submission_lstsq.csv')\n",
    "\n",
    "submission_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission obtained above scores 0.63806 in Kaggle's leaderboard.   The best score at the moment (02/06 at 19:08) is 0.68271."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19765.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.606628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.251880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Response\n",
       "count  19765.000000\n",
       "mean       5.606628\n",
       "std        2.251880\n",
       "min        1.000000\n",
       "25%        4.000000\n",
       "50%        6.000000\n",
       "75%        8.000000\n",
       "max        8.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('csvs/data_imputed.csv')\n",
    "features = data[data['train?'] == True].drop(['train?', 'Id', 'Response'], \n",
    "                                             axis=1)\n",
    "\n",
    "labels = data[data['train?'] == True]['Response'].astype('int') -1 \n",
    "\n",
    "submission_features = data[data['train?'] == False].drop(['train?', \n",
    "                                                          'Id', \n",
    "                                                          'Response'], \n",
    "                                                         axis=1)\n",
    "\n",
    "combo = ComboPredict(booster)\n",
    "\n",
    "# All of the models in booster were trained with fold=1:\n",
    "assert all(fold == 1 for _, fold, _ in booster.models)\n",
    "\n",
    "overall_cls_factor = 0.4\n",
    "score_submission = combo.predict_score(submission_features, overall_cls_factor)\n",
    "\n",
    "best_cutoffs = np.array([1.8277727, 2.67539148, 3.26617627, 3.9487634, \n",
    "                         4.79714536, 5.46358664, 6.07641931])\n",
    "yhcombo_submission = classify_with_cutoffs(score_submission, best_cutoffs)\n",
    "\n",
    "submission_ids = data[data['train?'] == False]['Id']\n",
    "submission_df = pd.DataFrame({\"Id\": submission_ids, \n",
    "                              \"Response\": yhcombo_submission.astype('int') + 1})\n",
    "\n",
    "submission_df = submission_df.set_index('Id')\n",
    "submission_df.to_csv('step03_submission_qwk.csv')\n",
    "\n",
    "submission_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission obtained here (`step03_submission_qwk.csv`) scores 0.66193 on Kaggle's leaderboard.  The best score at the moment 02/13 at 7:40 AM is 0.68325.  \n",
    "\n",
    "Spots 172 to 435 in the leaderboard are all tied at 0.67459."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
